{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we take the previously downloaded XML wikipedia data and show how it may be searched and catagorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XML of these articles is extremely rich with data and could be applied to all sorts of things. The biggest bottleneck is that is takes a long time and a lot of memory to iterate through the downloaded partitians for the purposes of extracting information. If that goal is achievedm, there are two main ways to categorize information. Through InfoBoxes that are placed on most article to apply a template. There are also Categories on articles placed by the author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attached blog goes into more detail on the processes mentioned here.\n",
    "https://towardsdatascience.com/wikipedia-data-science-working-with-the-worlds-largest-encyclopedia-c08efbac5f5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Austin\\\\.keras\\\\datasets\\\\enwiki-20191220-pages-articles9.xml-p1791081p2336422.bz2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bz2\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "data_path = r'C:\\Users\\Austin\\.keras\\datasets\\enwiki-20191220-pages-articles9.xml-p1791081p2336422.bz2'\n",
    "keras_home = r'C:\\Users\\Austin\\.keras\\datasets'\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test bz2 versus bzcat. \n",
    "The cells below test the run time of using bz2 versus bzcat to process 1 million lines of the compressed file. <br>\n",
    "The author of this notebook never could get bzcat to work properly, although it is much faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "lines = []\n",
    "for i, line in enumerate(bz2.BZ2File(data_path, 'r')):\n",
    "    lines.append(line)\n",
    "    if i > 1e6:\n",
    "        break  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = timer()\n",
    "lines = []\n",
    "\n",
    "for line in enumerate(subprocess.Popen('bzcat',\n",
    "                         shell = True,              \n",
    "                         stdin = open(data_path), \n",
    "                         stdout = subprocess.PIPE).stdout):\n",
    "    print(i)\n",
    "    lines.append(line)\n",
    "    if i > 1e6:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(lines[-250:-50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Parsing Approach**\n",
    "In order to get useful information from this data, we have to parse it on two levels.\n",
    "\n",
    "Extract the titles and article text from the XML <br>\n",
    "Extract relevant information from the article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "\n",
    "class WikiXmlHandler(xml.sax.handler.ContentHandler):\n",
    "    \"\"\"Content handler for Wiki XML data using SAX\"\"\"\n",
    "    def __init__(self):\n",
    "        xml.sax.handler.ContentHandler.__init__(self)\n",
    "        self._buffer = None\n",
    "        self._values = {}\n",
    "        self._current_tag = None\n",
    "        self._pages = []\n",
    "\n",
    "    def characters(self, content):\n",
    "        \"\"\"Characters between opening and closing tags\"\"\"\n",
    "        if self._current_tag:\n",
    "            self._buffer.append(content)\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        \"\"\"Opening tag of element\"\"\"\n",
    "        if name in ('title', 'text', 'timestamp'):\n",
    "            self._current_tag = name\n",
    "            self._buffer = []\n",
    "\n",
    "    def endElement(self, name):\n",
    "        \"\"\"Closing tag of element\"\"\"\n",
    "        if name == self._current_tag:\n",
    "            self._values[name] = ' '.join(self._buffer)\n",
    "\n",
    "        if name == 'page':\n",
    "            self._pages.append((self._values['title'], self._values['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Content handler for Wiki XML\n",
    "handler = WikiXmlHandler()\n",
    "\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "handler._pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Object for handling xml\n",
    "handler = WikiXmlHandler()\n",
    "\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "for i, line in enumerate(subprocess.Popen(['bzcat'], \n",
    "                         stdin = open(data_path),\n",
    "                         shell = True,\n",
    "                         stdout = subprocess.PIPE).stdout):\n",
    "    parser.feed(line)\n",
    "    print(i)\n",
    "    # Stop when 3 articles have been found\n",
    "    if len(handler._pages) > 2:\n",
    "        break\n",
    "        \n",
    "print([x[0] for x in handler._pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mwparserfromhell in c:\\users\\austin\\anaconda3\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mwparserfromhell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MHS', 'Picture Music International', \"St Mark's Eve\", 'Mount Sopris', 'Wikipedia:Articles for deletion/Andy Carrico', \"Saint Mark's Eve\", 'Goldschmidt Sex Scandal', 'Regional Technical College, Waterford', 'Mt. Sopris', 'SAMe', 'Herpes simplex virus 1', 'Herpes simplex virus 2', 'Damian Cray', 'Henry Preserved Smith', 'Arthur Seldon', 'Elk Range (California)', 'Sunburst Award', 'Gunn High', 'Seán Moore (Irish politician)', 'Damian cray', 'Taner Sağır', 'Line 6 (company)', 'Bertie Mee', 'Category:Value (ethics)', 'Paul Cullen (cardinal)', 'Wikipedia:WikiProject Swiss Municipalities', 'Paul Egede', 'Gregory Pakourianos', 'Private mortgage insurance', 'Category:Mountain ranges of British Columbia', 'Wikipedia:Wikiproject Swiss municipalities', 'Global positioning systems', 'Mexican labor law', 'Paul Emile Botta', 'Atlas Network', 'Yesler Terrace, Seattle', 'Regional technical college', 'Yakko Warner', 'Wikipedia:Articles for deletion/Invigilator', 'Paul Francois Barras', 'Paul Fleming (poet)', 'Wesley Anderson', 'Wikipedia:Wikipedia Signpost/2005-04-25/From the editor', 'Snowmass Mountain', 'Bryn railway station', 'Wakko Warner', 'North island college', 'Line6', 'Wikipedia:WikiProject Swiss municipalities/List of title variations', 'Implicit-association test', 'John M. Loh', 'Cammie King', 'Verreaux s Sifaka', 'PMI', 'Namco System 11', 'Snowmass', 'Paul Gavarni', 'Internet celebrities', 'Category:Compositions by Ralph Vaughan Williams', 'Template:Geocoordinate', 'GCIII', 'Painter and Limner', 'Turboraketti', 'Paul Johann Anselm von Feuerbach', 'Sulpice Chevalier', 'List of radio stations in Iowa', 'Acetylsalicylic', 'Bryn, Greater Manchester', 'Silent Diet', 'Quebec Autoroute 5', 'USS Relativity', 'Paul Johann Heyse', 'File:MassiveAttackProtection.jpg', 'Old Mother Riley', 'Ubi pus, ibi evacua', 'International Policy Network', 'Paul Joseph Barthez', 'PPD test', 'Paul Samosata', 'House of Dadiani', 'Paul Sarpi', 'Encyclopaedia of Islam', 'Ronald Fogleman', 'Josephine Butler', 'Windows nt', 'WXYC', 'Aspen/Snowmass', 'Complement cascade', 'Papal regalia', 'Peasant War', 'Bauernkrieg', 'The Malice at The Palace of Auburn Hills', 'Eitr', 'List of LGBT rights articles by region', 'Barnstaple Western Bypass', 'Ford Elite', 'Kurt Wimmer', 'Michael E. Ryan', 'Christen Andreas Fonnesbech', 'Pinhead.', 'Eric Carmen', 'Hope (disambiguation)', 'Three Sisters Recreation Area', 'Michelle Chong', 'Hirohiko Araki', 'Simpsons Bible Stories', 'Abdul Ameer Yousef Habeeb', 'Nontransposing instrument', 'Abercrombie and fitch', 'Smart antenna', \"Pedro Lopez d'Ayala\", 'May Maxwell', 'Aeronca', 'Muwenda Mutebi II', 'Pedro Lopez de Ayala', 'Son of a Preacher Man', 'Han Dynasty: A Period of Prosperity', 'Second Division', 'Serantes', 'Pelasgi', 'Muwenda Mutebi II of Buganda', 'Mutesa II', 'Prince of Wales Islands', 'South Pacific Area', 'Template:Israelpres', \"Diam's\", 'North Pacific Area', 'Ala (Roman allied military unit)', 'Central Pacific Area', 'Derviative of a function', 'Ala (odinani)', 'Jacob Estrup', 'USS Randolph (1776)', 'Derivative of a function', 'Wikipedia:Articles for deletion/Pootron bomb', 'Penitential Psalms', 'Psalms of Confession', 'Daudi Chwa', 'Daudi Chwa II', 'Peter Ramus', 'Daudi Cwa II', 'Peshawur', 'List of Turkish weightlifters', 'Pithom', 'Baden AG', 'Baden (AG)', 'Baden (Aargau)', 'Category:Igbo religion', 'Wikipedia:Articles for deletion/Kjetil', 'Pisidia', 'Reference class problem', 'Ibo (people)', 'Vancouver 2010', 'Category:Polish attack aircraft', 'Ibo people', 'Ndi igbo', 'Onye igbo', 'Ibos', 'Iben Hjejle', 'Igbos', 'Pinerolo', 'PPLB', 'Yushan National Park', 'Swining/Red Raw  &  Sore', 'Surfel', 'Lisa Gets an  \" A \"', 'Pietra Dura', 'Sonar 2087', 'List of Methodist theologians', \"Ryan's Fancy\", 'Pierre de Bourdeilles Brantome', 'Pierre de Brantome', 'Attack the Gas Station', 'Pentaceratops', 'Conspiracy to commit crimes against peace', 'Computer polygon', 'A. K. Fazlul Huq', 'The Lord of the Rings (movie)', 'List of peace prizes', 'Floyd Bennett', 'Wikipedia:Articles for deletion/List of conservative catchphrases', 'Planning, initiating and waging wars of aggression', 'History of nigeria', 'Racially profiled', 'Benguela railway', 'Jay Gavin', 'Pierre de Bocosel de Chastelard', 'Church of nigeria', 'Pierre de Boscosel de Chastelard', 'Nigerian Catholic Church', 'Nigerian catholic church', 'Stephen M. Cohen', 'Chevalier de Bayard', 'Nanoscientist', 'Daniel E. Barbey', 'Daniel Barbey', 'Eichstädt', 'Attack on the Gas Station', 'Kunzang Palyul Choling', 'Windsor Great Park', 'Eton Choirbook', 'Bishop Douglass School', 'Human Meta Human Vampiric Virus', 'Fortismere School', 'Julien Gracq', 'Leevi and the leavings', 'Music of West Africa', 'Dictionnaire des ouvrages anonymes et pseudonymes', 'West African music', 'Eichstädt (Bavaria)', 'Hito Steyerl', 'Wikipedia:Articles for deletion/Hollywood English', 'Dirac matrices', 'Bishop of Eichstädt', 'TVN24', 'USFDA', 'Buttermilk (disambiguation)', 'James Tour', 'John McFarland (Medal of Honor)', 'Sha-Na-Na', 'School of athens', 'BN pair', 'Pearl River Community College', 'Paul S. Weiss', 'Atomic Energy Act of 1946', 'The Book of Daniel (novel)', 'John Clapham (economic historian)', 'Shikharji', 'Aspen Mountain', 'ANZAC Avenue, Canberra', 'Asian witchcraft', 'Bert Sommer', 'Package tour', 'Kone Corporation', 'Fundão, Portugal', 'Richard Fleeshman', 'Correction (Stock market)', 'Duchy of Massa and Carrara', 'Fermanagh  &  South Tyrone (constituency)', 'Aspen Mountain (Colorado)', 'Powder down', 'North Atlantic drift', 'Francis Hopkinson Smith', 'Dynamic packaging', 'Borah High School', 'Newry  &  Armagh (constituency)', 'Angrivarii', 'Southern house spider', \"Democratic People's Movement\", 'Vaporator', 'Trick knee', 'Niwano Peace Prize', 'West Wind Drift', 'North Atlantic stream', 'Wikipedia:Wikipedia Signpost/2005-04-25/Papal scoop', \"Orvar-Odd's saga\", 'Board of Navy Commissioners', 'Wikipedia:Cleanup Taskforce/Silver ratio', 'Hervararkviða', 'Uniforms of the Imperial Japanese Army', 'North German Constitution', 'North Atlantic Stream', 'Fruit and Spice Park', 'Wikipedia:Articles for deletion/Magic Society of the White Flame', 'Tyrfing Cycle', 'National War Memorial (Newfoundland)', 'Template:Tyrfing', 'Cacodyl', \"Sinead O'connor\", 'Zambia Railways', 'Category:Transport in Wiltshire', 'Macon C. Overton', 'Brian Krause', 'Rene Thomas', 'U.N. Day', \"Sinead o'connor\", 'Template:Music of Indonesia', 'Nicholas Browne-Wilkinson', 'Category:Buildings and structures in Wiltshire', 'David Kirby (journalist)', 'UN Day', 'Category:Tourist attractions in Wiltshire', 'Igor Straminsky', 'Stannite', 'Decretum Gratiani', 'Lancelot Holland', 'O.G.S. Crawford', 'Osbert Guy Stanhope Crawford', 'Aspen Mountain (ski area)', 'Cardinal George de Amboise', 'Aspen Mountain Ski Area', 'Category:History of Wiltshire', 'Prince Iaukea', 'Eichstaett', 'Eichstatt', 'Atheos', 'Correction', 'St. Paul Outside the Walls', 'Sacrament of Confirmation', 'Decretum', 'Wikipedia:Articles for deletion/Asian witchcraft', \"Christ's College, East Finchley\", 'Wikipedia:Articles for deletion/Hardz', 'Proper Orthogonal Decomposition', 'Amende honorable', 'Railway spine', 'Cellular Traffic', 'Concordance of Discordant Canons', 'Glyn Edmund Daniel', 'Johann Amerbach', 'Dingo Fence', 'Star-Phoenix', 'Christopher Atkins', 'Israeli Parliament', 'Concordantia Discordantium Canonum', 'Bad Duerkheim', 'Bad Durkheim', \"Gratian's Decretum\", 'Symbian (company)', 'Parliament of Israel', 'Waw', 'William Penney, Baron Penney', 'Category:Salisbury', 'Exclusivist', 'Teallite', 'Forestville Mystery Cave State Park', 'American Fabius', 'Mezzanine (album)', '(148209) 2000 CR105', 'Northern Secondary School (Toronto)', 'Nectar in a Sieve', 'Gerhard lenski', 'HaShomer', 'Wikipedia:Articles for deletion/List of incidents famously considered great blunders', 'Category:Local government in Wiltshire', 'Parliamentary page', 'Wikipedia:Articles for deletion/Alexa Davis', 'Gratian, Decretum (Liège, University Library, MS 499)', 'Decretum Gratiani (Bibliothèque Nationale, MS lat. 3893)', 'Lucy Lane', 'Newmarket Transit Details', 'Bill Anderson (disambiguation)', 'Canons', 'Countdown to Infinite Crisis', 'Danzanryu', 'Dougie Freedman', 'Lord Amherst', 'Normality (behavior)', 'Deputy Chief of the Defence Staff', 'Højre', 'Gerhard Lenski', 'Marano', 'Wikipedia:Articles for deletion/Muathe research group', 'Chemotroph', 'County Constituency', 'Watson Lake, Yukon', 'Aurora Transit', 'Estrup', 'Music of nigeria', 'Nigeria music', \"Nigeria's music\", 'Forbidden Broadway, Vol. 3', 'Senninbari', 'Naija', 'Alzheimers', 'William Francis Grimes', \"Governor general's foot guards\", 'Thousand stitch belt', 'Somali Plate', 'Category:Mountain ranges of Massachusetts', 'Species (metaphysics)', 'Concordia discordantium canonum', 'Yoruba Mythology', 'Louis I the Pious', 'Pope Hadrian I', 'Sugaar', 'Dileep Kumar', 'Theory of a dead man', 'Aichi D1A', 'Clarington Transit', 'McKee Botanical Garden', 'Niels Thomasius Neergaard', 'A.R. Rehman', 'Hervör', 'Mystery Cave', 'Air Tractor', 'Diego Rodríguez de Silva y Velázquez', 'Forestville, Minnesota', 'Forestville, MN', 'Template:Venezuela-stub', 'King Matthias', 'Karachi University', 'Antigonish—Guysborough', 'Cape Breton South and Richmond', 'Organopalladium', 'Digby and Annapolis', 'Mathias Corvinus', 'W. H. L. Wallace', 'Yarmouth and Clare', 'Template:User id-1', 'Restigouche—Madawaska', 'Royal (electoral district)', 'St. John—Albert', 'Victoria—Carleton', 'Category:Organometallic chemistry', 'Châteauguay—Huntingdon', 'George-Étienne Cartier (electoral district)', 'Hull (electoral district)', \"L'Assomption—Montcalm\", 'Wikipedia:Peer review/LinuxQuestions.org/archive1', 'Laurier—Outremont', 'Laval—Two Mountains', 'Matane (electoral district)', 'Quebec South', 'St. Ann (electoral district)', 'Mi-17', 'St. Denis (electoral district)', 'St. Hyacinthe—Rouville', 'Japanese military ranks', 'Movado', 'St. Lawrence—St. George', 'Emperors of Vietnam', 'King Matthias I', 'Westmount—St. Henri', 'Wladislaus II', 'Fort William and Rainy River', 'Hum Hain Lajawab', 'William Wallace (disambiguation)', 'Glengarry and Stormont', 'Template:User id-2', 'Grey Southeast', 'Dodi al-Fayed', 'Lanark (electoral district)', 'Albert D. Sturtevant', 'Northumberland (Ontario electoral district)', 'No. 300  \" Land of Masovia \"  Polish Bomber Squadron', 'Emperor of Vietnam', 'Port Arthur and Kenora', 'Tommy the Cat', 'Englefield Green', 'Neepawa (electoral district)', 'Helder Camara', 'Springfield (electoral district)', 'Boroszlo', 'Journalistic standards and ethics', 'Hélder Câmara', 'Boroszló', 'Last Mountain (electoral district)', 'Heathcote Botanical Gardens', 'Maple Creek (electoral district)', 'Krakkó', 'Xuanye', 'Battle of Hafrsfjord', 'North Battleford (electoral district)', 'Template:User no-1', 'Steve Weinberg', 'Weyburn (federal electoral district)', 'USS Sturtevant', 'D. J. Fontana', 'Old Windsor', 'Resonance fm', 'Krakko', 'Bow River (electoral district)', 'East Calgary', 'Triglav Lakes Valley', 'Edmonton West', 'Hu Yao-bang', 'Lee Resolution', 'Comox—Alberni', 'MPEG Layer 2', 'The Battle In Hafrsfjord', 'Kootenay East', 'Journalism standards and ethics', 'Alcanena', 'Omega transmitter Paynesville', 'Kootenay West', 'Canada Arm', 'Skeena (electoral district)', 'C*S*H', 'Schnellbomber', 'Westminster District', 'University of Karachi', 'Triglav lakes valley', 'Earhart Foundation', 'Canada Arm 2', 'Gróttasöngr', 'Jean-François Allard', 'Ford Torino Elite', 'Template:Scroller', 'Polish 300 Bomber Squadron', \"Lee's Resolution\", 'Ford Gran Torino Elite', 'Hlödskvida', 'Bennie', 'Benavente, Portugal', 'International private law', 'Ituano FC', 'Treaty of Jeddah', 'Red wiggler', 'William Penn University', 'William Penn College', 'Wikipedia:Wikifun/Round 8/Answers/Question 13', 'Penn College', 'Missing years (Jewish calendar)', 'Bačka Topola', 'Pierre Nkurunziza', 'Homer Simpson in:  \" Kidney Trouble \"', 'Steve Soderstrom', 'Wikipedia:Articles for deletion/Snugglitis', 'Last Exit to Brooklyn', 'Nedoceratops', 'Omega Transmitter Paynesville', 'Constância', 'Mari (goddess)', 'Paul Hunn', 'Fraser Valley (electoral district)', 'Nintendo gamebooks', 'Vancouver—Burrard', 'Vancouver North', 'Professionalism', 'Athabaska (electoral district)', 'Camrose (electoral district)', 'Vegreville (electoral district)', 'Geriatocracy', 'Triglav lakes Valley', 'Ben Watson (footballer born 1985)', 'Long Lake (electoral district)', 'Melville (electoral district)', 'Seven Triglav Lakes', 'Wikipedia:Articles for deletion/Vapourbot', 'Rosetown (electoral district)', 'Amacc', 'South Battleford', 'Irreconcilables', 'Willow Bunch', 'Amacu', 'Lisa Pelikan', 'Amau', 'Johnny Weismuller', 'Double cream', 'St. Boniface (electoral district)', 'Seven Lakes Valley', 'Aziza (African mythology)', 'Brantford City', 'Dufferin—Simcoe', 'Netaji: Subhas Chandra Bose: The Forgotten Hero', 'Conventional set', 'Essex West (electoral district)', 'Fort William (electoral district)', 'Frontenac—Addington', 'USS Childs (DD-241)', 'Grenville—Dundas', 'Hamilton South (electoral district)', 'NHL Conference Finals', 'Hastings South', 'Hastings—Peterborough', 'Forbidden Hollywood (parody)', 'Kenora—Rainy River', 'Kanapaha Botanical Gardens', 'District of Beja (Portugal)', 'Kingston City', 'Zubeidaa', 'Replacement Killers', 'Wikipedia:WikiProject Moldova', 'Dolton, Devon', 'Ethnolinguist', 'Calls', 'Muskoka—Ontario', 'Norfolk—Elgin', 'Ontario (electoral district)', 'Extreme Engineering', 'Bishop of Hereford (Robin Hood)', 'Port Arthur—Thunder Bay', 'SS Flandre (1951)', 'Prince Edward—Lennox', 'USS Childs (AVP-14)', 'Toronto East Centre', 'USS Childs (AVD-1)', '1995 NHL Stanley Cup Playoffs', 'Richard Edwards', 'Wikipedia:Articles for deletion/Log/2005 April 25', 'Wikipedia:Categories for deletion/Log/2005 April 25', 'Toronto Northeast', 'Toronto Northwest', 'Toronto West Centre', 'Toronto—High Park', 'Tony Popovic', 'B lymphocytes', 'Toronto—Scarborough', 'Styracosaurus', 'Argyll and Bute (UK Parliament constituency)', 'Nathaniel Thurmond', 'File:Uniao barbarense football.png', 'Cape Breton North—Victoria', 'Digby—Annapolis', 'Kathie Lee', 'Aljustrel', 'Hants—Kings', 'Loretta Sell Hildegarde', 'Wikipedia:TL', 'Queens—Lunenburg', 'French-indian war', 'União Agrícola Barbarense Futebol Clube', 'Richmond—West Cape Breton', 'Shelburne—Yarmouth', 'Cartier (electoral district)', 'Charlevoix—Saguenay', 'União Barbarense', 'Lake St. John (electoral district)', 'Joseph Evans Sperry', 'Michael Winslow', 'Québec—Montmorency', 'St. Henri (electoral district)', 'Almodôvar', 'Three Rivers—St. Maurice', 'Wikipedia:Cleanup Taskforce/Members', 'Gap project', 'Alligator lizard', 'Ryoga Hibiki', 'Alvito, Portugal', 'Kaiba Corporation', 'Wikipedia:Articles for deletion/Davis Fields', 'Mayored to the Mob', 'Emmaus Walk', 'Human T cell lymphotropic virus type I', 'Wikipedia:Articles for deletion/Revotes on Vfd', 'Destinos', 'Human T cell lymphotropic virus type II', 'Pinkies', 'Barrancos', 'File:Crisis on Infinite Earths issue 1 cover.jpg', 'Great Turkish War \"', 'Alcohol nitrites', 'Lorenzo Campeggio', 'Abdul Aziz Said', 'Wikipedia:Articles for deletion/Green Alliance', 'Quebec Autoroute 20', 'NHL Eastern Conference Final', 'Wikipedia:Articles for deletion/White powder', 'Sentence (grammar)', 'Directional gyro', 'Wikipedia:Articles for deletion/Jeff Dennison', 'San Diego Northern Railway', 'William Knox', 'Paolo Avitabile', 'Wampa', 'I Will Remember You (Angel)', 'Blue Mink', 'Wikipedia:Articles for deletion/Michael w. dean', 'Wikipedia:Template standardisation/comparison', '1993 Newbury by-election', 'Soviet Union at the 1988 Summer Olympics', 'Joseph evans sperry', 'Category:Culture of Korea', 'No. 300 Polish Bomber Squadron', 'Wikipedia:Articles for deletion/Transcendence Galactic Archive', 'Fred DeLuca', 'Pachyrhinosaurus', '300th Bomber Command', 'Shammy', \"Wikipedia:Articles for deletion/AMP'D\", 'Wikipedia:Articles for deletion/Snotex', 'Grothendieck site', 'James Wilkinson (disambiguation)', 'Rope dart', 'Steak  &  Shake', 'Frank launder', 'File:Ogniem i Mieczem plakat.jpg', 'Chain Whip', 'Grand National Curling Club', '3CG Records', 'Jean-Baptiste Ventura', 'File:Kurtandcourtneydvd.jpg', 'Stishovite', 'John Kirwan', 'Wikipedia:Articles for deletion/Sosuave', 'No. 300  \" Masovia \"  Polish Bomber Squadron', 'File:MusicologyCover.jpg', 'South Korea at the 1988 Summer Olympics', 'Bundesautobahn 7', 'Toby Amies', 'Amy Pietz', 'Messeturm', 'Category:Images of cities', 'Arbir', 'Equidistributed mod 1', 'Mawanella', 'Toby amies', 'Downset', 'Michael Jackson (actor)', 'Chinese Amazons', 'Wikipedia:Articles for deletion/The Sect of Homokaasu', 'MesseTurm', 'Vidigueira', 'Serpa', 'Ourique', 'Odemira', 'Moura, Portugal', 'Mértola', 'Ferreira do Alentejo', 'Cuba, Portugal', 'Castro Verde', 'Henry Yevele', 'The Initiative (Buffy the Vampire Slayer episode)', 'Einiosaurus', 'Saint-Mathieu-de-Beloeil', 'Forbidden Broadway Strikes Back', 'Maldon  &  Tiptree F.C.', 'Penicillinase', 'Category:Lists of towns', 'Maximum a posteriori estimation', 'Galena Nuclear Power Plant', 'Topolya', 'Wikipedia:Articles for deletion/Tali Waterman', 'United States at the 1988 Summer Olympics', 'Linkage principle', 'File:Nazgul.PNG', 'Saint-Charles-sur-Richelieu, Quebec', 'Helensburgh and Lomond', 'District of Setúbal (Portugal)', 'Mali Iđoš', 'Category:Transport in Cheshire', 'I Killed the Prom Queen', 'Netherlands at the 1988 Summer Olympics', 'Kubuna', 'Wikipedia:Articles for deletion/Lucy Bayliss', 'Nazca Desert', 'Category:Local government in Cheshire', 'Shoot the gap', 'Kishegyes', 'Hughes Supply', 'Fischer oxazole synthesis', 'Deprotonating', 'The Indigo Children', 'Coase', 'Wikipedia:Articles for deletion/Thomas Eisenmann', 'Achelousaurus', 'Medco Health Solutions', 'Equidistribution mod 1', 'Avondale School (Wiltshire)', 'Deerfoot Trail', 'Two-level game theory', 'Nose guard', 'Achelosaurus', 'Wampas', 'Alberta Highway 2A', 'Wikipedia:Articles for deletion/Aaron Scott', 'Category:Chester', 'Great Britain at the 1988 Summer Olympics', 'Sainte-Marie-Madeleine, Quebec', 'Mario Golf Toadstool Tour', 'James David Whittemore', 'Lac qui Parle River', 'Mario Golf Advance Tour', 'File:Wiedzmin plakat.jpg', 'Crystal children', 'Category:Tourist attractions in Cheshire', 'Primatial Basilica of the Blessed Virgin Mary Assumed Into Heaven and St Adalbert', 'Slyne Head Lighthouse', 'Brinjal', 'R2', 'Óbecse', 'Category:History of Cheshire', 'R3', 'Whitebread', 'Tracheophyte', 'Sweden at the 1988 Summer Olympics', 'Sainte-Madeleine, Quebec', 'Virtual band', 'Boy (I Need You)', 'Category:Genie Award winners', 'Wild Card (TV series)', 'Iskandariyah', 'Wikipedia:Cleanup Taskforce/Standardized test', 'Passaconaway', 'Testamentum Flavianum', 'Wikipedia:Cleanup Taskforce/Proctor', 'Template:TOC001', 'Apollonia (Illyria)', 'Finland at the 1988 Summer Olympics', 'Baldassare Peruzzi', 'Category:Parliamentary constituencies in Cheshire', 'Francis Caracciolo', 'La Présentation, Quebec', 'Alabama Power', 'Category:Genie Award winning films', 'Justin Metsing Lekhanya', 'France at the 1988 Summer Olympics', 'Alandroal', 'Order of Suvarov', 'Subhash Ghai', 'R21 (New York City Subway car)', 'Australia at the 1988 Summer Olympics', 'William Hervy Lamb Wallace', 'Taal (film)', 'Arraiolos Municipality', 'Brigadier-general W.H.L. Wallace', 'Wikipedia:Articles for deletion/The smoke signal', 'Sandmeyer reaction', 'Category:Thursday Next series', 'Category:Nations at the 1988 Summer Olympics', 'William Hervey Lamb Wallace', 'General W.H.L. Wallace', 'Jewbilee', 'Borba, Portugal', 'Estremoz Municipality', 'Democratic movements', 'Brigadier-general William Hervey Lamme Wallace', 'Japan at the 1988 Summer Olympics', 'Willie Davis', 'Brigadier general William Hevey Lamme Wallace', 'Sale of the century', 'Scott Savol', 'Saint-Simon, Montérégie, Quebec', 'William Harvey Lamb Wallace', 'William Harvey Lamme Wallace', 'Open Arms (Mariah Carey single)', 'Pride of the Southland Band', 'List of User Friendly characters', 'Condyloma acuminatum', 'Category:Daytime Emmy Award winners', 'Combo television unit', 'Composite video input', 'Nucleoside reverse transcriptase inhibitors', 'Non-nucleoside reverse transcriptase inhibitors', 'Protease inhibitors', 'Saint-Liboire', 'TV/DVD combo', 'Antiretroviral drugs', 'Abu Zayd al-Balkhi', 'Adenopathy', 'Centrosaurus', 'Tubu, Botswana', 'Wikipedia:Featured article candidates/Polish Constitution of May 3, 1791', 'Bagha Purana', 'Opm', 'Sanjay Leela Bhansali', 'Sainte-Hélène-de-Bagot, Quebec', 'Serum glutamic pyruvate transaminase', 'SGPT', 'Lake Martin', 'Burebasaga', 'Category:Consonants', 'Boiler Room Girls', 'Buffalo Niagara Medical Campus', 'Muhammad Zarrindast', 'Kaante', 'American Jobs', 'Carta Magna', 'Serum glutamic oxaloacetic transaminase', 'Sgot', 'USS King (DD-242)', \"Bringin' On the Heartbreak\", 'The Coast Is Never Clear', 'Mitch Landrieu', 'Randal Kleiser', 'Brønsted acid', 'File:SeoulTowerView.jpg', 'Gary Birdsong', 'Hypothetical contract', 'Río Cuarto, Córdoba', 'U value', 'World of Motion', 'Fire Birds', 'Liberalism is a mental disorder', 'Sowell', 'Ivan Raidenovitch Raikov', 'Forestville State Park', 'Mystery Cave State Park', 'File:OPM - Menace To Sobriety.jpg', 'Sherman Anti-trust Act', 'Discourse particle', 'Stakeholder theory', 'Aspen Skiing Company', 'Jayant Patel', 'Alexandra Christina Manley', 'Growth failure', 'Ita Buttrose', 'Neal Matthews Jr.', 'North Canyon High School', 'Category:Education in Cheshire', 'Tovata', 'Grand general', 'Al-Hasan ibn Mūsā ibn Shākir', 'Ntfombi of Eswatini', 'Lake Louise State Park', 'Queen Ntombi', 'Clifford group', 'Fire birds', 'Category:Gemini Award winners', 'Raikov', 'Irig, Serbia', 'Universal Indicator (collective)', 'Zarrin dast', 'Imperial Japanese Navy Land Forces', 'Pit Preacher', 'Category:Alkyl nitrites', 'File:Monumen Nasional View.jpg', \"Ja'far Muhammad ibn Mūsā ibn Shākir\", 'Consistency criterion', 'USS Sands (DD-243)', 'The Taming of the Shrew (disambiguation)', 'USS Sands (APD-13)', 'Malcom in the middle', 'Wilmer Stultz', 'Wikipedia:Notes for Japan-related articles', 'Five-and-dime', 'Josef Papp', 'Michael Murphy (actor)', 'Sir Joh Bjelke-Petersen', 'Liberal intergovernmentalism', 'Keraunography', 'Mark Lester', 'Sir Joh', 'Failure to thrive', 'The Official Preppy Handbook', 'Template:Nobility of Fiji', 'Ronald Rice', 'Wikipedia:Peer review/Jeb Bush/archive1', 'Keranography', 'Prince Emanuele Filiberto of Italy', 'Wikipedia:Articles for deletion/Sweetback', 'Warner-Amex Satellite Entertainment Company', 'Francis Newall, 2nd Baron Newall', 'Ashpenaz', 'Proclamation of Rebellion', 'Ahmad ibn Mūsā ibn Shākir', 'Bioelectric', 'Psi3', 'Above the line', 'Proclamation for Supressing Rebellion and Sedition', 'Entry-level job', 'Above-the-line', 'File:Bantha.png', 'Shadakshari', 'Entry level job', 'Private members’ bills', 'Both Sides Now (Joni Mitchell album)', 'USS Williamson (DD-244)', 'Argument Clinic', 'Danny Nucci', 'Second Bill of Rights', 'Below-the-line', 'Cluny Macpherson (physician)', 'Category:Lakes of Alabama', 'Francis Storer Eaton Newall, 2nd Baron Newall', 'Tom Hardy', 'Auckland Islands Marine Reserve', 'Forgent', 'Henry McNamara', 'Pegasus galaxy (Stargate)', 'USS Exeter (Star Trek)', 'Reagan coalition', 'Liancourt Islands', 'Entry level worker', 'Entry-level worker', 'Nørre Åby', 'Weak verbs', 'Raymond Lesinak', 'Pegasus dwarf', 'Dijkstra algo', 'Copula (probability theory)', 'Benito de Soto', 'Dwarf Galaxy', 'Uncle Jesse', 'South U.S.', 'Wikipedia:Articles for deletion/Han capital', 'G3 (concert)', 'Heatherette', 'Reception theory', 'Northeast Minneapolis', 'Ahmad ibn Farrokh', 'MAX Yellow Line', 'Pthread', 'Republika (band)', 'Neil Cassady', 'List of Ottawa Senators head coaches', 'Wikipedia:Articles for deletion/Reception theory', 'Kapiri Mposhi', '109th Congress', 'List of twin towns and sister cities in the United Kingdom', 'The Last Samurai (2003)', 'Thundercracker', 'Jean Gottman', 'Meat Recovery System', 'Monument Gardens (Baháʼí World Centre)', 'Clairemont High School', 'Meat recovery system', 'Meat recovery', 'Zire 31', 'City of Port Augusta', 'Dil Se..', 'Stephen Hero', \"Ahmad ibn 'Imad al-Din\", 'Garrison hat', 'Kentucky Derby Festival', 'Bill  \" Swish \"  Nicholson', 'Cape Breton North and Victoria', 'Pen Drawing', '65th Grey Cup', 'Colchester—Hants']\n"
     ]
    }
   ],
   "source": [
    "# Object for handling xml\n",
    "handler = WikiXmlHandler()\n",
    "\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "for i, line in enumerate(bz2.BZ2File(data_path, 'r')):\n",
    "    \n",
    "    parser.feed(line)\n",
    "    \n",
    "    # Stop when 3 articles have been found\n",
    "    if len(handler._pages) >1000:\n",
    "        break\n",
    "        \n",
    "print([x[0] for x in handler._pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Object for handling xml\n",
    "handler = WikiXmlHandler()\n",
    "\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "for i, line in enumerate(bz2.BZ2File(data_path, 'r')):\n",
    "    parser.feed(line)\n",
    "    \n",
    "    # Stop when 50 articles have been found\n",
    "    if len(handler._pages) > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taner Sağır\n"
     ]
    }
   ],
   "source": [
    "import mwparserfromhell \n",
    "\n",
    "print(handler._pages[20][0])\n",
    "\n",
    "# Create the wiki article\n",
    "wiki = mwparserfromhell.parse(handler._pages[20][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mwparserfromhell.wikicode.Wikicode'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{{BLP sources|date=November 2009}} \\n {{Infobox sportsperson \\n | name           = Taner Sağır \\n | ima'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(wiki))\n",
    "wiki[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72 wikilinks.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Turkey',\n",
       " 'Kardzhali',\n",
       " 'Bulgaria',\n",
       " 'Turkey',\n",
       " 'Olympic weightlifting',\n",
       " 'Ankara',\n",
       " 'Weightlifting at the Summer Olympics',\n",
       " '2004 Summer Olympics',\n",
       " \"Weightlifting at the 2004 Summer Olympics – Men's 77 kg\",\n",
       " 'World Weightlifting Championships',\n",
       " '2006 World Weightlifting Championships',\n",
       " 'European Weightlifting Championships',\n",
       " '2004 European Weightlifting Championships',\n",
       " '2005 European Weightlifting Championships',\n",
       " '2007 European Weightlifting Championships',\n",
       " 'Kardzhali',\n",
       " 'Bulgaria',\n",
       " 'Turkey',\n",
       " 'Olympic weightlifting',\n",
       " '2004 Summer Olympics',\n",
       " 'snatch (weightlifting)',\n",
       " 'clean and jerk',\n",
       " 'Turks in Bulgaria',\n",
       " 'Yenimahalle, Ankara',\n",
       " 'Pursaklar, Ankara',\n",
       " 'Nezir Sağır',\n",
       " 'Hürriyet',\n",
       " 'Ankara',\n",
       " '2008 Summer Olympics',\n",
       " 'Sibel Güler',\n",
       " 'Hürriyet',\n",
       " 'Athens',\n",
       " 'Greece',\n",
       " 'Santo Domingo',\n",
       " 'Dominican Republic',\n",
       " 'Hermosillo',\n",
       " 'Mexico',\n",
       " 'Sofia',\n",
       " 'Bulgaria',\n",
       " 'Kiev',\n",
       " 'Ukraine',\n",
       " 'Havířov',\n",
       " 'Czech Republic',\n",
       " 'Stavanger',\n",
       " 'Norway',\n",
       " 'Košice',\n",
       " 'Slovakia',\n",
       " 'Turkey',\n",
       " 'Athens',\n",
       " 'Greece',\n",
       " 'Sergey Filimonov',\n",
       " 'Kazakhstan',\n",
       " 'Athens',\n",
       " 'Greece',\n",
       " 'Oleg Perepetchenov',\n",
       " 'Russia',\n",
       " 'Athens',\n",
       " 'Greece',\n",
       " 'Category:1985 births',\n",
       " 'Category:Living people',\n",
       " 'Category:Turkish male weightlifters',\n",
       " 'Category:Bulgarian Turks in Turkey',\n",
       " 'Category:Bulgarian emigrants to Turkey',\n",
       " 'Category:Olympic weightlifters of Turkey',\n",
       " 'Category:Olympic gold medalists for Turkey',\n",
       " 'Category:Weightlifters at the 2004 Summer Olympics',\n",
       " 'Category:Weightlifters at the 2008 Summer Olympics',\n",
       " 'Category:People from Kardzhali',\n",
       " 'Category:Olympic medalists in weightlifting',\n",
       " 'Category:European champions in weightlifting',\n",
       " 'Category:Medalists at the 2004 Summer Olympics',\n",
       " 'Category:European champions for Turkey']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikilinks = [x.title for x in wiki.filter_wikilinks()]\n",
    "print(f'There are {len(wikilinks)} wikilinks.')\n",
    "wikilinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wiki.filter_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.filter_comments()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out everything you can do with mwparserfromhell, read the docs.\n",
    "https://mwparserfromhell.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 external links.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(None, 'http://arama.hurriyet.com.tr/arsivnews.aspx?id=10535466'),\n",
       " (None,\n",
       "  'http://www.sabah.com.tr/SabahSpor/TumSporlar/2011/10/10/taner-sagirdan-haltere-veda'),\n",
       " (None, 'http://www.hurriyet.de/haberler/son-dakika/163264/haber'),\n",
       " ('Taner Sağır at Lift Up',\n",
       "  'http://www.chidlovski.net/liftup/l_athleteStatsResult.asp?a_id=599')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_links = [(x.title, x.url) for x in wiki.filter_external_links()]\n",
    "print(f'There are {len(external_links)} external links.')\n",
    "external_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[[Turkey|Turkish]]', mwparserfromhell.nodes.wikilink.Wikilink)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can search specific words.\n",
    "contemporary = wiki.filter(matches = 'Turkey')\n",
    "contemporary[1], type(contemporary[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taner Sağır (born March 13, 1985 in Kardzhali, Bulgaria) is a Turkish world and Olympic weightliftin'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.strip_code().strip()[:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infoboxes are the easiest way to segment wiki articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25 templates.\n",
      "BLP sources\n",
      "Infobox sportsperson \n",
      " \n",
      "birth date and age\n",
      "height\n",
      "MedalCompetition\n",
      "MedalGold\n",
      "MedalCompetition\n",
      "MedalGold\n",
      "MedalCompetition\n",
      "MedalGold\n",
      "MedalGold\n",
      "MedalBronze\n",
      "cite news \n",
      "cite news \n",
      "Gold medal\n",
      "Gold medal\n",
      "Gold medal\n",
      "Gold medal\n",
      "Gold medal\n",
      "Gold medal\n",
      "Gold medal\n",
      "Silver medal\n",
      "reflist\n",
      "Footer Olympic Champions Weightlifting Middleweight\n",
      "DEFAULTSORT:Sagir, Taner\n"
     ]
    }
   ],
   "source": [
    "templates = wiki.filter_templates()\n",
    "print(f'There are {len(templates)} templates.')\n",
    "for template in templates:\n",
    "    print(template.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{{BLP sources|date=November 2009}}',\n",
       " \"{{Infobox sportsperson \\n | name           = Taner Sağır \\n | image          =  \\n | imagesize      = \\n | caption        =  \\n | birth_name     = \\n | fullname       =  \\n | nickname       =  \\n | nationality    = [[Turkey|Turkish]] \\n | residence      =  \\n | birth_date     = {{birth date and age|1985|3|13}}  \\n | birth_place    = [[Kardzhali]], [[Bulgaria]] \\n | height         = {{height|m=1.70}} \\n | weight         =  \\n | website        = \\n | country        = [[Turkey]] \\n | sport          = [[Olympic weightlifting|Weightlifting]] \\n | event          =  & ndash;77 kg \\n | collegeteam    =  \\n | club           = Demirspor Club, [[Ankara]] \\n | team           =  \\n | turnedpro      =  \\n | coach          = Muharrem Süleymanoğlu and Osman Nuri Vural  \\n | retired        =  \\n | coaching       =  \\n | worlds         =  \\n | regionals      =  \\n | nationals      =  \\n | olympics       =  \\n | paralympics    =  \\n | highestranking =  \\n | pb             =  \\n | medaltemplates =  \\n {{MedalCompetition|[[Weightlifting at the Summer Olympics|Olympic Games]]}} \\n {{MedalGold|[[2004 Summer Olympics|2004 Athens]]|[[Weightlifting at the 2004 Summer Olympics – Men's 77 kg| & ndash;77 kg]]}} \\n {{MedalCompetition|[[World Weightlifting Championships|World Championships]]}} \\n {{MedalGold|[[2006 World Weightlifting Championships|2006 Santo Domingo]]| & ndash;77 kg}} \\n {{MedalCompetition|[[European Weightlifting Championships|European Championships]]}} \\n {{MedalGold|[[2004 European Weightlifting Championships|2004 Kiev]]| & ndash;77 kg}} \\n {{MedalGold|[[2005 European Weightlifting Championships|2005 Sofia]]| & ndash;77 kg}} \\n {{MedalBronze|[[2007 European Weightlifting Championships|2007 Strasbourg]]| & ndash;77 kg}} \\n | show-medals    =  \\n }}\",\n",
       " '{{birth date and age|1985|3|13}}',\n",
       " '{{height|m=1.70}}',\n",
       " '{{MedalCompetition|[[Weightlifting at the Summer Olympics|Olympic Games]]}}',\n",
       " \"{{MedalGold|[[2004 Summer Olympics|2004 Athens]]|[[Weightlifting at the 2004 Summer Olympics – Men's 77 kg| & ndash;77 kg]]}}\",\n",
       " '{{MedalCompetition|[[World Weightlifting Championships|World Championships]]}}',\n",
       " '{{MedalGold|[[2006 World Weightlifting Championships|2006 Santo Domingo]]| & ndash;77 kg}}',\n",
       " '{{MedalCompetition|[[European Weightlifting Championships|European Championships]]}}',\n",
       " '{{MedalGold|[[2004 European Weightlifting Championships|2004 Kiev]]| & ndash;77 kg}}',\n",
       " '{{MedalGold|[[2005 European Weightlifting Championships|2005 Sofia]]| & ndash;77 kg}}',\n",
       " '{{MedalBronze|[[2007 European Weightlifting Championships|2007 Strasbourg]]| & ndash;77 kg}}',\n",
       " '{{cite news |url=http://arama.hurriyet.com.tr/arsivnews.aspx?id=10535466 |newspaper=[[Hürriyet]] |title=Taner Sağır: Olimpiyatlar her şeyi değiştirdi |date=2008-12-09 |language=Turkish |accessdate=2012-07-31 }}',\n",
       " '{{cite news |url=http://www.hurriyet.de/haberler/son-dakika/163264/haber |newspaper=[[Hürriyet]] |title=Şampiyonlar evlendi |date=2008-08-30 |language=Turkish |accessdate=2012-12-15 }}',\n",
       " '{{Gold medal}}',\n",
       " '{{Gold medal}}',\n",
       " '{{Gold medal}}',\n",
       " '{{Gold medal}}',\n",
       " '{{Gold medal}}',\n",
       " '{{Gold medal}}',\n",
       " '{{Gold medal}}',\n",
       " '{{Silver medal}}',\n",
       " '{{reflist}}',\n",
       " '{{Footer Olympic Champions Weightlifting Middleweight}}',\n",
       " '{{DEFAULTSORT:Sagir, Taner}}']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{{Infobox sportsperson \\n | name           = Taner Sağır \\n | image          =  \\n | imagesize      = \\n | caption        =  \\n | birth_name     = \\n | fullname       =  \\n | nickname       =  \\n | nationality    = [[Turkey|Turkish]] \\n | residence      =  \\n | birth_date     = {{birth date and age|1985|3|13}}  \\n | birth_place    = [[Kardzhali]], [[Bulgaria]] \\n | height         = {{height|m=1.70}} \\n | weight         =  \\n | website        = \\n | country        = [[Turkey]] \\n | sport          = [[Olympic weightlifting|Weightlifting]] \\n | event          =  & ndash;77 kg \\n | collegeteam    =  \\n | club           = Demirspor Club, [[Ankara]] \\n | team           =  \\n | turnedpro      =  \\n | coach          = Muharrem Süleymanoğlu and Osman Nuri Vural  \\n | retired        =  \\n | coaching       =  \\n | worlds         =  \\n | regionals      =  \\n | nationals      =  \\n | olympics       =  \\n | paralympics    =  \\n | highestranking =  \\n | pb             =  \\n | medaltemplates =  \\n {{MedalCompetition|[[Weightlifting at the Summer Olympics|Olympic Games]]}} \\n {{MedalGold|[[2004 Summer Olympics|2004 Athens]]|[[Weightlifting at the 2004 Summer Olympics – Men's 77 kg| & ndash;77 kg]]}} \\n {{MedalCompetition|[[World Weightlifting Championships|World Championships]]}} \\n {{MedalGold|[[2006 World Weightlifting Championships|2006 Santo Domingo]]| & ndash;77 kg}} \\n {{MedalCompetition|[[European Weightlifting Championships|European Championships]]}} \\n {{MedalGold|[[2004 European Weightlifting Championships|2004 Kiev]]| & ndash;77 kg}} \\n {{MedalGold|[[2005 European Weightlifting Championships|2005 Sofia]]| & ndash;77 kg}} \\n {{MedalBronze|[[2007 European Weightlifting Championships|2007 Strasbourg]]| & ndash;77 kg}} \\n | show-medals    =  \\n }}\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infobox = wiki.filter_templates(matches = 'Infobox sportsperson')[0]\n",
    "infobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Taner Sağır',\n",
       " 'image': '',\n",
       " 'imagesize': '',\n",
       " 'caption': '',\n",
       " 'birth_name': '',\n",
       " 'fullname': '',\n",
       " 'nickname': '',\n",
       " 'nationality': 'Turkish',\n",
       " 'residence': '',\n",
       " 'birth_date': '',\n",
       " 'birth_place': 'Kardzhali, Bulgaria',\n",
       " 'height': '',\n",
       " 'weight': '',\n",
       " 'website': '',\n",
       " 'country': 'Turkey',\n",
       " 'sport': 'Weightlifting',\n",
       " 'event': '& ndash;77 kg',\n",
       " 'collegeteam': '',\n",
       " 'club': 'Demirspor Club, Ankara',\n",
       " 'team': '',\n",
       " 'turnedpro': '',\n",
       " 'coach': 'Muharrem Süleymanoğlu and Osman Nuri Vural',\n",
       " 'retired': '',\n",
       " 'coaching': '',\n",
       " 'worlds': '',\n",
       " 'regionals': '',\n",
       " 'nationals': '',\n",
       " 'olympics': '',\n",
       " 'paralympics': '',\n",
       " 'highestranking': '',\n",
       " 'pb': '',\n",
       " 'medaltemplates': '',\n",
       " 'show-medals': ''}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information = {param.name.strip_code().strip(): param.value.strip_code().strip() for param in infobox.params}\n",
    "information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_article(title, text, timestamp, template = 'Infobox book'):\n",
    "    \"\"\"Process a wikipedia article looking for template\"\"\"\n",
    "    \n",
    "    # Create a parsing object\n",
    "    wikicode = mwparserfromhell.parse(text)\n",
    "    \n",
    "    # Search through templates for the template\n",
    "    matches = wikicode.filter_templates(matches = template)\n",
    "    \n",
    "    # Filter out errant matches\n",
    "    matches = [x for x in matches if x.name.strip_code().strip().lower() == template.lower()]\n",
    "    \n",
    "    if len(matches) >= 1:\n",
    "        # template_name = matches[0].name.strip_code().strip()\n",
    "\n",
    "        # Extract information from infobox\n",
    "        properties = {param.name.strip_code().strip(): param.value.strip_code().strip() \n",
    "                      for param in matches[0].params\n",
    "                      if param.value.strip_code().strip()}\n",
    "\n",
    "        # Extract internal wikilinks\n",
    "        wikilinks = [x.title.strip_code().strip() for x in wikicode.filter_wikilinks()]\n",
    "\n",
    "        # Extract external links\n",
    "        exlinks = [x.url.strip_code().strip() for x in wikicode.filter_external_links()]\n",
    "\n",
    "        # Find approximate length of article\n",
    "        text_length = len(wikicode.strip_code().strip())\n",
    "\n",
    "        return (title, properties, wikilinks, exlinks, timestamp, text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = process_article('Taner Sağır', wiki, None)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Taner Sağır',\n",
       " {'name': 'Taner Sağır',\n",
       "  'nationality': 'Turkish',\n",
       "  'birth_place': 'Kardzhali, Bulgaria',\n",
       "  'country': 'Turkey',\n",
       "  'sport': 'Weightlifting',\n",
       "  'event': '& ndash;77 kg',\n",
       "  'club': 'Demirspor Club, Ankara',\n",
       "  'coach': 'Muharrem Süleymanoğlu and Osman Nuri Vural'})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = process_article('Taner Sağır', wiki, None, template = 'Infobox sportsperson')\n",
    "r[0], r[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Manager modified for finding books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiXmlHandler(xml.sax.handler.ContentHandler):\n",
    "    \"\"\"Parse through XML data using SAX\"\"\"\n",
    "    def __init__(self):\n",
    "        xml.sax.handler.ContentHandler.__init__(self)\n",
    "        self._buffer = None\n",
    "        self._values = {}\n",
    "        self._current_tag = None\n",
    "        self._books = []\n",
    "        self._article_count = 0\n",
    "        self._non_matches = []\n",
    "\n",
    "    def characters(self, content):\n",
    "        \"\"\"Characters between opening and closing tags\"\"\"\n",
    "        if self._current_tag:\n",
    "            self._buffer.append(content)\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        \"\"\"Opening tag of element\"\"\"\n",
    "        if name in ('title', 'text', 'timestamp'):\n",
    "            self._current_tag = name\n",
    "            self._buffer = []\n",
    "\n",
    "    def endElement(self, name):\n",
    "        \"\"\"Closing tag of element\"\"\"\n",
    "        if name == self._current_tag:\n",
    "            self._values[name] = ' '.join(self._buffer)\n",
    "\n",
    "        if name == 'page':\n",
    "            self._article_count += 1\n",
    "            # Search through the page to see if the page is a book\n",
    "            book = process_article(**self._values, template = 'Infobox book')\n",
    "            # Append to the list of books\n",
    "            if book:\n",
    "                self._books.append(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched through 510 articles to find 3 books.\n"
     ]
    }
   ],
   "source": [
    "# Object for handling xml\n",
    "handler = WikiXmlHandler()\n",
    "\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "for i, line in enumerate(bz2.BZ2File(data_path, 'r')):\n",
    "    parser.feed(line)\n",
    "    \n",
    "    # Stop when 3 articles have been found\n",
    "    if len(handler._books) > 2:\n",
    "        break\n",
    "        \n",
    "print(f'Searched through {handler._article_count} articles to find 3 books.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The Book of Daniel (novel)',\n",
       " {'1': '< !-- See Wikipedia:WikiProject Novels or Wikipedia:WikiProject Books -- >',\n",
       "  'name': 'The Book of Daniel',\n",
       "  'title_orig': 'The Book of Daniel',\n",
       "  'image': 'TheBookOfDaniel.jpg',\n",
       "  'border': 'yes',\n",
       "  'caption': 'First edition',\n",
       "  'author': 'E. L. Doctorow',\n",
       "  'country': 'US',\n",
       "  'language': 'English',\n",
       "  'genre': 'Fiction',\n",
       "  'publisher': 'Random House',\n",
       "  'pub_date': '1971',\n",
       "  'media_type': 'Hardcover',\n",
       "  'pages': '303',\n",
       "  'isbn': '978-0-8129-7817-9',\n",
       "  'congress': 'PS3554.O3 B6 2007',\n",
       "  'oclc': '141385012'},\n",
       " ['Wikipedia:WikiProject Novels',\n",
       "  'Wikipedia:WikiProject Books',\n",
       "  'E. L. Doctorow',\n",
       "  'Random House',\n",
       "  'E. L. Doctorow',\n",
       "  'Julius and Ethel Rosenberg',\n",
       "  'The Guardian',\n",
       "  'The New York Times',\n",
       "  'Book of Daniel',\n",
       "  'Project MUSE',\n",
       "  'Disneyland',\n",
       "  'Daniel (1983 movie)',\n",
       "  'Sidney Lumet',\n",
       "  'Morton Sobell',\n",
       "  'David Greenglass',\n",
       "  'Paul Robeson',\n",
       "  'Peekskill Riots',\n",
       "  'Category:1971 American novels',\n",
       "  'Category:American historical novels',\n",
       "  'Category:American novels adapted into films',\n",
       "  'Category:Novels by E. L. Doctorow',\n",
       "  'Category:Random House books',\n",
       "  'Category:Cultural depictions of Julius and Ethel Rosenberg'],\n",
       " ['https://www.theguardian.com/books/booksblog/2015/sep/15/the-book-of-daniel-el-doctorow-reading-group',\n",
       "  'https://www.nytimes.com/1971/07/04/archives/the-book-of-daniel-by-e-l-doctorow-303-pp-new-york-random-house-695.html',\n",
       "  'https://muse.jhu.edu/article/432542',\n",
       "  'https://www.nytimes.com/1971/06/07/books/doctorow-daniel.html',\n",
       "  'https://www.jstor.org/discover/10.2307/29533549?uid=3739744'],\n",
       " '2019-03-15T07:15:57Z',\n",
       " 5037)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler._books[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 19410000 lines so far.\n",
      "Searched through 257498 articles.\n",
      "\n",
      "Found 982 books in 2049 seconds.\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "# Object for handling xml\n",
    "handler = WikiXmlHandler()\n",
    "\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "# Parse the entire file\n",
    "for i, line in enumerate(bz2.BZ2File(data_path, 'r')):\n",
    "    if (i + 1) % 10000 == 0:\n",
    "        print(f'Processed {i + 1} lines so far.', end = '\\r')\n",
    "    try:\n",
    "        parser.feed(line)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    \n",
    "end = timer()\n",
    "books = handler._books\n",
    "\n",
    "print(f'\\nSearched through {handler._article_count} articles.')\n",
    "print(f'\\nFound {len(books)} books in {round(end - start)} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one partition took almost 30 minutes. \n",
    "We definitely need to consider parallelization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Computing\n",
    "We have a large amount of data and it takes a very long time \n",
    "to compute it sequentially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, at this point, my project changed slightly to use the SQL data. I never made any real <br>\n",
    "headway into doing this properly. All attempts has issues with Windows and Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
